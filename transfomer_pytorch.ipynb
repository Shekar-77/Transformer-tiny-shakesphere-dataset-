{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99daa383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31e3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\himan\\downloads\\pinecone\\.conda\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd85ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf9ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "import wget\n",
    "url=\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "download=wget.download(url)\n",
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a10516",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt','r',encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b19bd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48bc5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "stoi={ch:i for i,ch in enumerate(chars)}\n",
    "itos={i:ch for i,ch in enumerate(chars)}\n",
    "encode=lambda s:[stoi[c] for c in s]\n",
    "decode=lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49baadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.tensor(encode(text),dtype=torch.long)\n",
    "n=int(len(data)*0.9)\n",
    "train=data[:n]\n",
    "val=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a24f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "block_size=256\n",
    "n_emd=384\n",
    "max_iters=5000\n",
    "n_heads=6\n",
    "dropout=0.2\n",
    "n_layer=6\n",
    "device=\"cpu\"\n",
    "eval_iters=200\n",
    "eval_interval=2000\n",
    "l_r=3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c741eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.query=nn.Linear(n_emd,head_size,bias=False)\n",
    "        self.key=nn.Linear(n_emd,head_size,bias=False)\n",
    "        self.value=nn.Linear(n_emd,head_size,bias=False)\n",
    "        self.register_buffer('tril',torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        b,t,c=x.shape\n",
    "        k=self.query(x)\n",
    "        q=self.query(x)\n",
    "        v=self.value(x)\n",
    "\n",
    "        wei=q@k.transpose(-2,-1)*k.shape[-1]**-0.5\n",
    "        wei=wei.masked_fil(self.tril[:t,:t]==0 ,float('-inf'))\n",
    "        wei=F.softmax(wei,dim=-1)\n",
    "        wei=self.dropout(wei)\n",
    "        out=wei@v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb22011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiheadattention(nn.Module):\n",
    "    def __init__(self, n_heads,head_size):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([head(head_size) for _ in range(n_heads) ])\n",
    "        self.proj=nn.Linear(n_heads*head_size,n_emd)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=torch.cat([h(x) for h in self.heads],dim=-1)\n",
    "        out=self.dropout(self.proj(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b90427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embds):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(n_embds,4*n_embds),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embds,n_embds),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2052ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, n_embds, n_head):\n",
    "        super().__init__()\n",
    "        head_size=n_embds//n_head\n",
    "        self.sa=Multiheadattention(n_head,head_size)\n",
    "        self.fwd=FeedForward(n_embds)\n",
    "        self.n1=nn.LayerNorm(n_embds)\n",
    "        self.n2=nn.LayerNorm(n_embds)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=x+self.sa(self.n1(x))\n",
    "        x=x+self.fwd(self.n2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f03a23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gptlanguagemodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding=nn.Embedding(vocab_size,n_emd)\n",
    "        self.positional_embedding=nn.Embedding(block_size,n_emd)\n",
    "        self.layer=nn.LayerNorm(n_emd)\n",
    "        self.leniar=nn.Linear(n_emd,vocab_size)\n",
    "        self.blocks=nn.Sequential(*[block(n_emd,n_heads) for _ in range(n_layer)])\n",
    "\n",
    "        self.apply(self._init_weight)\n",
    "\n",
    "    def _init_weight(self,module):\n",
    "        if isinstance(module,nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight,mean=0.0,std=0.2)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module,nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight,mean=0.0,std=0.2)\n",
    "    \n",
    "    def forward(self,idx,target=None):\n",
    "        b,t=idx.shape\n",
    "        embedding=self.token_embedding(idx)\n",
    "        position=self.positional_embedding(torch.arange(t,device=device))\n",
    "        out=embedding+position\n",
    "        out=self.blocks(out)\n",
    "        out=self.layer(out)\n",
    "        logits=self.leniar(out)\n",
    "\n",
    "        if target==None:\n",
    "            loss=None\n",
    "\n",
    "        else:\n",
    "            b,t,c=locals.shape\n",
    "            logits=logits.view(b*t,c)\n",
    "            target=target.view(b*t)\n",
    "            loss=F.cross_entropy(logits,target)\n",
    "\n",
    "        return logits,loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range (max_new_tokens):\n",
    "            idx_cond=idx[:,-block_size:]\n",
    "            logits,loss=self(idx_cond)\n",
    "            logits=logits[:,-1,:]\n",
    "            probs=F.softmax(logits,dim=-1)\n",
    "            idx_next=torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx,idx_next),dim=1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fda017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=gptlanguagemodel()\n",
    "m=model.to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=l_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iters in range(max_iters):\n",
    "    xb,yb=get_batch('data')\n",
    "    logits,loss=model(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iters%eval_interval==0 or iters==max_iters-1:\n",
    "        print(f\"The the loss obtained in {iters} is {loss}\")\n",
    "    \n",
    "\n",
    "context=torch.zeros((1,1),dtype=torch.long,device=device)\n",
    "print(decode(m.generate(context,max_new_tokens=500)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb673b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data1 = train if split=='data' else val\n",
    "    ix=torch.randint(len(data1)-block_size,(batch_size,))\n",
    "    x=torch.stack([data1[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data1[i+1:i+block_size+1] for i in ix])\n",
    "    x,y=x.to(device),y.to(device)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a71987f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 256)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b,t=x.shape\n",
    "b,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ddf03e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 384]) torch.Size([256, 384])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 384])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=get_batch(data)\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "x[:10]\n",
    "yo=nn.Embedding(block_size,n_emd) \n",
    "yo1=nn.Embedding(vocab_size,n_emd)\n",
    "yo3=yo1(x)\n",
    "yo4=yo(torch.arange(t,device=device)) \n",
    "print(yo3.shape,yo4.shape)\n",
    "yo2=yo3+yo4\n",
    "yo2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7779c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
